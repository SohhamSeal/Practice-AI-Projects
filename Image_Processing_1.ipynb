{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Processing #1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th9xRm3vzg7z"
      },
      "source": [
        "Problem Statement: [Image Processing #1\r\n",
        "](https://docs.google.com/document/d/1LMhYqu-Yvn38eIJV5-_1re4BOXxvcBybYgtc6ChrQ2U/edit#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKOdaKeoznNI"
      },
      "source": [
        "## Importing Library and Data\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLEOnaoxzeDZ"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as datasets\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn import datasets\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWsKS91O0Y3R"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "os.getcwd()\r\n",
        "labels = pd.read_csv(r'/content/drive/MyDrive/Sohham/Verzeo/train.csv')\r\n",
        "submission = pd.read_csv(r'/content/drive/MyDrive/Sohham/Verzeo/sample_submission.csv')\r\n",
        "train_path = r'/content/drive/MyDrive/Verzeo/train/'\r\n",
        "test_path = r'/content/drive/MyDrive/Verzeo/test/'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdvGcpvEjoyF"
      },
      "source": [
        "## Just displaying the data to get an idea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Xx87sLAaDLSn",
        "outputId": "b0ae74e5-b4de-457d-b7be-f4d1d932daa7"
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>has_cactus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id  has_cactus\n",
              "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
              "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
              "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
              "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
              "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxfGLldCDevu",
        "outputId": "1111a409-0641-4963-c742-f4c6b66bcd94"
      },
      "source": [
        "labels['has_cactus'].value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    13136\n",
              "0     4364\n",
              "Name: has_cactus, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2441Blim0lc4"
      },
      "source": [
        "## Image Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipMf_RES0juo"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def imshow(image, ax=None, title=None, normalize=True):\r\n",
        "    if ax is None:\r\n",
        "        fig, ax = plt.subplots()\r\n",
        "    image = image.numpy().transpose((1, 2, 0))\r\n",
        "\r\n",
        "    if normalize:\r\n",
        "        mean = np.array([0.485, 0.456, 0.406])\r\n",
        "        std = np.array([0.229, 0.224, 0.225])\r\n",
        "        image = std * image + mean\r\n",
        "        image = np.clip(image, 0, 1)\r\n",
        "\r\n",
        "    ax.imshow(image)\r\n",
        "    ax.spines['top'].set_visible(False)\r\n",
        "    ax.spines['right'].set_visible(False)\r\n",
        "    ax.spines['left'].set_visible(False)\r\n",
        "    ax.spines['bottom'].set_visible(False)\r\n",
        "    ax.tick_params(axis='both', length=0)\r\n",
        "    ax.set_xticklabels('')\r\n",
        "    ax.set_yticklabels('')\r\n",
        "\r\n",
        "    return ax"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq1HUVtB1BRB"
      },
      "source": [
        "class CactiDataset(Dataset):\r\n",
        "    def __init__(self, data, path , transform = None):\r\n",
        "        super().__init__()\r\n",
        "        self.data = data.values\r\n",
        "        self.path = path\r\n",
        "        self.transform = transform\r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data)\r\n",
        "    \r\n",
        "    def __getitem__(self,index):\r\n",
        "        img_name,label = self.data[index]\r\n",
        "        img_path = os.path.join(self.path, img_name)\r\n",
        "        image = img.imread(img_path)\r\n",
        "        if self.transform is not None:\r\n",
        "            image = self.transform(image)\r\n",
        "        return image, label"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMk8v3ggj3GQ"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg90JqgB1CAh"
      },
      "source": [
        "train_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\r\n",
        "\r\n",
        "test_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\r\n",
        "\r\n",
        "valid_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeKbYqjEj79g"
      },
      "source": [
        "## Splitting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHtbvp1mE_y0"
      },
      "source": [
        "train, valid_data = train_test_split(labels, stratify=labels.has_cactus, test_size=0.2)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qyCYVB3FBrc"
      },
      "source": [
        "train_data = CactiDataset(train, train_path, train_transform )\r\n",
        "valid_data = CactiDataset(valid_data, train_path, valid_transform )\r\n",
        "test_data = CactiDataset(submission, test_path, test_transform )"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIAdfwtSFEC0"
      },
      "source": [
        "num_epochs = 40\r\n",
        "num_classes = 2\r\n",
        "batch_size = 28\r\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bznr6RTuFGSl",
        "outputId": "89cd3ba2-cd01-4774-a763-f43727cb06fa"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "device"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCwfcV3pFIsn"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=0)\r\n",
        "valid_loader = DataLoader(dataset = valid_data, batch_size = batch_size, shuffle=False, num_workers=0)\r\n",
        "test_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtcVBY6OFLlJ"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def imshow(image, ax=None, title=None, normalize=True):\r\n",
        "    if ax is None:\r\n",
        "        fig, ax = plt.subplots()\r\n",
        "    image = image.numpy().transpose((1, 2, 0))\r\n",
        "    if normalize:\r\n",
        "        mean = np.array([0.485, 0.456, 0.406])\r\n",
        "        std = np.array([0.229, 0.224, 0.225])\r\n",
        "        image = std * image + mean\r\n",
        "        image = np.clip(image, 0, 1)\r\n",
        "    ax.imshow(image)\r\n",
        "    ax.spines['top'].set_visible(False)\r\n",
        "    ax.spines['right'].set_visible(False)\r\n",
        "    ax.spines['left'].set_visible(False)\r\n",
        "    ax.spines['bottom'].set_visible(False)\r\n",
        "    ax.tick_params(axis='both', length=0)\r\n",
        "    ax.set_xticklabels('')\r\n",
        "    ax.set_yticklabels('')\r\n",
        "    return ax"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzWK2Cb3kL3y"
      },
      "source": [
        "## Designing a Convolution Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZptT59kFWRx"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "class CNN(nn.Module): \r\n",
        "    def __init__(self):\r\n",
        "        super(CNN, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3)\r\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\r\n",
        "        self.conv2_drop = nn.Dropout2d()\r\n",
        "        self.fc1 = nn.Linear(720, 1024)\r\n",
        "        self.fc2 = nn.Linear(1024, 2)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\r\n",
        "        x = x.view(x.shape[0],-1)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.dropout(x, training=self.training)\r\n",
        "        x = self.fc2(x)\r\n",
        "        return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3tiSgjFZB_"
      },
      "source": [
        "CNNmodel = CNN()\r\n",
        "#print(CNNmodel)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fBfjl1Zkln8"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K6_KjG_Fasu"
      },
      "source": [
        "CNNmodel = CNN().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPogylvmkk7D"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdsPNvdwFeCY",
        "outputId": "c1085bda-d2ad-4bf7-ab2b-ea3d249c5d82"
      },
      "source": [
        "train_losses = []\r\n",
        "valid_losses = []\r\n",
        "\r\n",
        "for epoch in range(1, num_epochs + 1):\r\n",
        "    train_loss = 0.0\r\n",
        "    valid_loss = 0.0\r\n",
        "    CNNmodel.train()\r\n",
        "    for data, target in train_loader:\r\n",
        "        data = data.to(device)\r\n",
        "        target = target.to(device)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        output = CNNmodel(data)\r\n",
        "        loss = criterion(output, target)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        train_loss += loss.item() * data.size(0)\r\n",
        "        \r\n",
        "    CNNmodel.eval()\r\n",
        "    for data, target in valid_loader:\r\n",
        "        data = data.to(device)\r\n",
        "        target = target.to(device)\r\n",
        "        output = CNNmodel(data)\r\n",
        "        loss = criterion(output, target)\r\n",
        "        valid_loss += loss.item()*data.size(0)\r\n",
        "    \r\n",
        "    train_loss = train_loss/len(train_loader.sampler)\r\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\r\n",
        "    train_losses.append(train_loss)\r\n",
        "    valid_losses.append(valid_loss)\r\n",
        "        \r\n",
        "    print('Epoch: {} \\tTraining Loss: {:f} \\tValidation Loss: {:f}'.format(epoch, train_loss, valid_loss))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.731736 \tValidation Loss: 0.727068\n",
            "Epoch: 2 \tTraining Loss: 0.732469 \tValidation Loss: 0.727068\n",
            "Epoch: 3 \tTraining Loss: 0.731606 \tValidation Loss: 0.727068\n",
            "Epoch: 4 \tTraining Loss: 0.730158 \tValidation Loss: 0.727068\n",
            "Epoch: 5 \tTraining Loss: 0.731417 \tValidation Loss: 0.727068\n",
            "Epoch: 6 \tTraining Loss: 0.731719 \tValidation Loss: 0.727068\n",
            "Epoch: 7 \tTraining Loss: 0.731849 \tValidation Loss: 0.727068\n",
            "Epoch: 8 \tTraining Loss: 0.731751 \tValidation Loss: 0.727068\n",
            "Epoch: 9 \tTraining Loss: 0.730549 \tValidation Loss: 0.727068\n",
            "Epoch: 10 \tTraining Loss: 0.731521 \tValidation Loss: 0.727068\n",
            "Epoch: 11 \tTraining Loss: 0.731990 \tValidation Loss: 0.727068\n",
            "Epoch: 12 \tTraining Loss: 0.730913 \tValidation Loss: 0.727068\n",
            "Epoch: 13 \tTraining Loss: 0.731452 \tValidation Loss: 0.727068\n",
            "Epoch: 14 \tTraining Loss: 0.730983 \tValidation Loss: 0.727068\n",
            "Epoch: 15 \tTraining Loss: 0.731615 \tValidation Loss: 0.727068\n",
            "Epoch: 16 \tTraining Loss: 0.731192 \tValidation Loss: 0.727068\n",
            "Epoch: 17 \tTraining Loss: 0.732024 \tValidation Loss: 0.727068\n",
            "Epoch: 18 \tTraining Loss: 0.731688 \tValidation Loss: 0.727068\n",
            "Epoch: 19 \tTraining Loss: 0.731629 \tValidation Loss: 0.727068\n",
            "Epoch: 20 \tTraining Loss: 0.731066 \tValidation Loss: 0.727068\n",
            "Epoch: 21 \tTraining Loss: 0.732805 \tValidation Loss: 0.727068\n",
            "Epoch: 22 \tTraining Loss: 0.731940 \tValidation Loss: 0.727068\n",
            "Epoch: 23 \tTraining Loss: 0.731150 \tValidation Loss: 0.727068\n",
            "Epoch: 24 \tTraining Loss: 0.731491 \tValidation Loss: 0.727068\n",
            "Epoch: 25 \tTraining Loss: 0.731853 \tValidation Loss: 0.727068\n",
            "Epoch: 26 \tTraining Loss: 0.731785 \tValidation Loss: 0.727068\n",
            "Epoch: 27 \tTraining Loss: 0.731979 \tValidation Loss: 0.727068\n",
            "Epoch: 28 \tTraining Loss: 0.731379 \tValidation Loss: 0.727068\n",
            "Epoch: 29 \tTraining Loss: 0.731522 \tValidation Loss: 0.727068\n",
            "Epoch: 30 \tTraining Loss: 0.731900 \tValidation Loss: 0.727068\n",
            "Epoch: 31 \tTraining Loss: 0.731214 \tValidation Loss: 0.727068\n",
            "Epoch: 32 \tTraining Loss: 0.731217 \tValidation Loss: 0.727068\n",
            "Epoch: 33 \tTraining Loss: 0.731589 \tValidation Loss: 0.727068\n",
            "Epoch: 34 \tTraining Loss: 0.731205 \tValidation Loss: 0.727068\n",
            "Epoch: 35 \tTraining Loss: 0.730262 \tValidation Loss: 0.727068\n",
            "Epoch: 36 \tTraining Loss: 0.731235 \tValidation Loss: 0.727068\n",
            "Epoch: 37 \tTraining Loss: 0.731495 \tValidation Loss: 0.727068\n",
            "Epoch: 38 \tTraining Loss: 0.731866 \tValidation Loss: 0.727068\n",
            "Epoch: 39 \tTraining Loss: 0.731736 \tValidation Loss: 0.727068\n",
            "Epoch: 40 \tTraining Loss: 0.730499 \tValidation Loss: 0.727068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8luUS0alGz4"
      },
      "source": [
        "Finally Testing the model on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5CCpeSkFgns",
        "outputId": "c3528602-5197-4a64-8de6-421896c86032"
      },
      "source": [
        "model.eval() \r\n",
        "with torch.no_grad():\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    for images, labels in valid_loader:\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        outputs = model(images)\r\n",
        "        _,predicted = torch.max(outputs.data, 1)\r\n",
        "        total += labels.size(0)\r\n",
        "        correct += (predicted == labels).sum().item()\r\n",
        "          \r\n",
        "    print('Accuracy of the model on the test dataset: {} %'.format(100 * correct/total))\r\n",
        "\r\n",
        "torch.save(model.state_dict(), 'CNNmodel.ckpt')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test dataset: 99.6 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}